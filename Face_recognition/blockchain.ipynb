{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"blockchain.ipynb","provenance":[{"file_id":"13FpGG6QEMFFUg6rQmVtTAni98ZqtEQD9","timestamp":1638714943556}],"collapsed_sections":[],"authorship_tag":"ABX9TyPt9BRSAElE65Ep4C2Zg/+M"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"iKNo0pFsUhOi"},"source":["# **Reconnaissance de visages de la base donnée**"]},{"cell_type":"code","metadata":{"id":"q__seBCvvf3u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638733170838,"user_tz":-60,"elapsed":32794,"user":{"displayName":"ACHRAF TARIFA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjYAvYJOrsbWvHSuzVlyNvomPA_4nbqyWhKxCm=s64","userId":"05763537258238423581"}},"outputId":"f848a1f3-1c4c-483a-8b57-0e8f0406cafd"},"source":["!pip install face_recognition"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting face_recognition\n","  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n","Collecting face-recognition-models>=0.3.0\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","\u001b[K     |████████████████████████████████| 100.1 MB 22 kB/s \n","\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566185 sha256=f45be7c5b2e7975e1951715623f5f62d557baa553f773cf32b6074ba3bde24e7\n","  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face-recognition\n","Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"]}]},{"cell_type":"code","metadata":{"id":"EeDyV2V-vy0O","executionInfo":{"status":"ok","timestamp":1638736909297,"user_tz":-60,"elapsed":490,"user":{"displayName":"ACHRAF TARIFA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjYAvYJOrsbWvHSuzVlyNvomPA_4nbqyWhKxCm=s64","userId":"05763537258238423581"}}},"source":["import face_recognition\n","import numpy as np\n","import shutil\n","import os\n","import smtplib\n","import imghdr\n","import cv2\n","import time\n","from datetime import datetime"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"cQzsqONxwUnU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638733506585,"user_tz":-60,"elapsed":5679,"user":{"displayName":"ACHRAF TARIFA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjYAvYJOrsbWvHSuzVlyNvomPA_4nbqyWhKxCm=s64","userId":"05763537258238423581"}},"outputId":"3e222088-6ac2-494e-d913-264fda7f016d"},"source":["known_face_encodings = []\n","known_face_names = []\n","i=0\n","directory = r'/content/GI3S1'\n","for filename in os.listdir(directory):\n","  image = face_recognition.load_image_file(os.path.join(directory, filename))\n","  face_encoding = face_recognition.face_encodings(image)[0]\n","  known_face_encodings.append(face_encoding)\n","  known_face_names.append(filename[:-4])\n","  print(\"reconnaissance terminée avec succès pour \"+filename[:-4])"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["reconnaissance terminée avec succès pour jhon\n","reconnaissance terminée avec succès pour achraf\n","reconnaissance terminée avec succès pour maria\n","reconnaissance terminée avec succès pour nadine\n"]}]},{"cell_type":"markdown","metadata":{"id":"9fx7ALRxVbEF"},"source":["# **Définiton de la fonction autorisation**"]},{"cell_type":"code","metadata":{"id":"LFT1rIhT0tC8","executionInfo":{"status":"ok","timestamp":1638733511185,"user_tz":-60,"elapsed":326,"user":{"displayName":"ACHRAF TARIFA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjYAvYJOrsbWvHSuzVlyNvomPA_4nbqyWhKxCm=s64","userId":"05763537258238423581"}}},"source":["def autorisation():\n","  test = 0\n","  dir = r'/content/temp'\n","  for file in os.listdir(dir):\n","    # Load an image with an unknown face\n","    unknown_image = face_recognition.load_image_file(os.path.join(dir, file))\n","    name = \"unknown\"\n","    # Find all the faces and face encodings in the unknown image\n","    face_locations = face_recognition.face_locations(unknown_image)\n","    face_encodings = face_recognition.face_encodings(unknown_image, face_locations)\n","    os.remove(os.path.join(dir, file))\n","    # Loop through each face found in the unknown image\n","    for face_encoding in face_encodings:\n","      # See if the face is a match for the known face(s)\n","      matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n","      # Or instead, use the known face with the smallest distance to the new face\n","      face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n","      best_match_index = np.argmin(face_distances)\n","      if matches[best_match_index]:\n","        name = known_face_names[best_match_index]\n","        test = 1\n","        break\n","  return name\n","    "],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pdfongX-U-Zd"},"source":["# **Lecture video ou live cam et détection des visages**"]},{"cell_type":"code","metadata":{"id":"nty9TF-MF5uP","executionInfo":{"status":"ok","timestamp":1638737106465,"user_tz":-60,"elapsed":341,"user":{"displayName":"ACHRAF TARIFA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjYAvYJOrsbWvHSuzVlyNvomPA_4nbqyWhKxCm=s64","userId":"05763537258238423581"}}},"source":["#cap = cv2.VideoCapture(0) for live cam\n","cap = cv2.VideoCapture('/content/test4.mp4')\n","t_end = time.time()\n","face_cascade = cv2.CascadeClassifier('/content/haarcascade_frontalface_default.xml')"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q3X9p-uQGDhD","colab":{"base_uri":"https://localhost:8080/","height":487},"executionInfo":{"status":"error","timestamp":1638737139969,"user_tz":-60,"elapsed":28822,"user":{"displayName":"ACHRAF TARIFA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjYAvYJOrsbWvHSuzVlyNvomPA_4nbqyWhKxCm=s64","userId":"05763537258238423581"}},"outputId":"33389675-a37e-4f7d-a0aa-f2399f7ec99b"},"source":["presentList = dict()\n","while True:\n","    _, img = cap.read()\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    \n","    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n","    if faces != () :\n","      for (x, y, w, h) in faces:\n","        cv2.imwrite(\"/content/temp/frame%d.jpg\" % count, img)\n","        nom = autorisation()\n","        if nom!=\"unknown\" and nom not in presentList:\n","          print(nom + \" est present\")\n","          now = datetime.now()\n","          dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n","          presentList[nom]=dt_string"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n","  \n"]},{"output_type":"stream","name":"stdout","text":["nadine est present\n","achraf est present\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-b41a069106e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/temp/frame%d.jpg\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautorisation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnom\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m\"unknown\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnom\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpresentList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" est present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-577cccb7f12a>\u001b[0m in \u001b[0;36mautorisation\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"unknown\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Find all the faces and face encodings in the unknown image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mface_locations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mface_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_encodings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_locations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36mface_locations\u001b[0;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_trim_css_to_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_rect_to_css\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_raw_face_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cnn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_trim_css_to_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_rect_to_css\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_raw_face_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36m_raw_face_locations\u001b[0;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcnn_face_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbrfcEOHJ9ek","executionInfo":{"status":"ok","timestamp":1638738377913,"user_tz":-60,"elapsed":554,"user":{"displayName":"ACHRAF TARIFA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjYAvYJOrsbWvHSuzVlyNvomPA_4nbqyWhKxCm=s64","userId":"05763537258238423581"}},"outputId":"d1d8b934-9092-4f6f-f870-1031078dca87"},"source":["presentList"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'achraf': '05/12/2021 20:45:32', 'nadine': '05/12/2021 20:45:14'}"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"6Vf3-KD2YW8-","executionInfo":{"status":"ok","timestamp":1638738418407,"user_tz":-60,"elapsed":513,"user":{"displayName":"ACHRAF TARIFA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjYAvYJOrsbWvHSuzVlyNvomPA_4nbqyWhKxCm=s64","userId":"05763537258238423581"}}},"source":["import csv \n","a_file = open(\"/content/presentlist.csv\", \"w\")\n","\n","writer = csv.writer(a_file)\n","writer.writerow([\"name\", \"Date\"])\n","for key, value in presentList.items():\n","    writer.writerow([key, value])\n","\n","a_file.close()"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"9FnO3NRLbfBr","executionInfo":{"status":"ok","timestamp":1638738577776,"user_tz":-60,"elapsed":335,"user":{"displayName":"ACHRAF TARIFA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjYAvYJOrsbWvHSuzVlyNvomPA_4nbqyWhKxCm=s64","userId":"05763537258238423581"}}},"source":["def ListToBlockchain():\n","    \n","    file= open(\"/content/presentlist.csv\")\n","    next(file)\n","\n","    resultat=[]\n","    for row in file:\n","        numb = row.split(',')[0]\n","        resultat.append(numb)\n","    print(resultat)\n","    return resultat"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9CAcAfTncO0D","executionInfo":{"status":"ok","timestamp":1638738919552,"user_tz":-60,"elapsed":358,"user":{"displayName":"ACHRAF TARIFA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjYAvYJOrsbWvHSuzVlyNvomPA_4nbqyWhKxCm=s64","userId":"05763537258238423581"}},"outputId":"bc1682b1-9317-4da8-a9e4-8fab59f140f2"},"source":["ListToBlockchain()"],"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["['nadine', 'achraf']\n"]},{"output_type":"execute_result","data":{"text/plain":["['nadine', 'achraf']"]},"metadata":{},"execution_count":47}]}]}